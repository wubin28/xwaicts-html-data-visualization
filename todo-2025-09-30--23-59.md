# ICMwRIPER-5 PLAN — Data Dashboard for Agentic AI Performance Dataset

This plan specifies the exact implementation steps to read the Excel dataset, compute three metrics, and generate a static, mobile-friendly HTML dashboard. No code is written here; implementation will happen only after approval and entering EXECUTE mode.

## Agreed Decisions
- Virtual environment: Reuse existing venv. Only consider rebuild if verification fails and with explicit authorization.
- Columns: Use best judgment with robust detection and normalization.
- Visualization stack: Simple, beginner-friendly — Matplotlib/Seaborn to generate inline SVG, embedded into a static HTML file with minimal CSS.
- Small-sample & ties: No sample-size threshold; always pick Top 3. If scores tie, break ties by alphabetical group name. Display sample size on bars/labels for clarity.
- Row count card: Show read_rows and processed_rows (union of rows contributing to any of the three metrics). Display both at the top of the dashboard.

## Files (exact names)
- Input: first-80-rows-agentic_ai_performance_dataset_20250622.xlsx (project root)
- Python: analyze_data.py (project root)
- HTML: data-dashboard.html (project root)
- Log (optional): data_processing.log (append-only, project root)

## Data Semantics & Normalization Rules
- Column detection (case-insensitive, flexible matching):
  - agent_type: prefer exact 'agent_type'; fallback candidates include ['agent type', 'type', 'agenttype'].
  - model_architecture: prefer exact 'model_architecture'; fallback ['model architecture', 'architecture', 'modelarch'].
  - task_category: prefer exact 'task_category'; fallback ['task category', 'task', 'taskcategory'].
  - multimodal_capability (boolean): prefer exact 'multimodal_capability'; fallback candidates containing both tokens 'multimodal' and 'capab' (substring) in any order; also try ['is_multimodal', 'supports_multimodal'].
  - bias detection (numeric): prefer exact 'bias detection' or 'bias_detection'; fallback substrings including 'bias' and 'detect'.
- multimodal_capability value mapping to boolean True/False:
  - True set: {True, 1, '1', 'true', 'yes', 'y', 't', '支持', '是'} (case-insensitive, trimmed)
  - False set: {False, 0, '0', 'false', 'no', 'n', 'f', '不支持', '否'}
  - Other/NaN -> missing; rows with missing cannot contribute to multimodal proportions.
- bias detection: cast to numeric (pandas to_numeric with errors='coerce'); non-parsable -> NaN

## Metric Definitions
- Q1: Top 3 agent_type by multimodal proportion
  - For each agent_type group: proportion = count(multimodal=True) / count(multimodal in {True, False})
  - Exclude rows where agent_type missing OR multimodal missing.
  - Rank by proportion desc; tie-break by agent_type ascending; take first 3.
- Q2: Top 3 model_architecture by multimodal proportion
  - Same as Q1 with group column = model_architecture.
- Q3: Top 3 task_category by bias detection median
  - For each task_category group: median over valid numeric bias detection values.
  - Exclude rows where task_category missing OR bias detection is NaN.
  - Rank by median desc; tie-break by task_category ascending; take first 3.

## Processed Row Counting
- read_rows = total rows after reading Excel (len(df)).
- processed_rows = the union of rows that contribute to any of the three metrics:
  - rows used in Q1 (agent_type present & multimodal parsed boolean)
  - rows used in Q2 (model_architecture present & multimodal parsed boolean)
  - rows used in Q3 (task_category present & bias detection numeric)
- Display both counts at the top of the dashboard.

## HTML/CSS Structure (static, mobile-friendly, light theme)
- Single self-contained HTML (data-dashboard.html) with:
  - <head>: UTF-8 meta, responsive viewport, embedded minimal CSS (system font stack, light background, white cards with subtle shadow, responsive single-column on mobile).
  - <body> sections:
    1) Header: title, subtitle (source file name + generation timestamp), small methods note
    2) Stats row: two cards showing read_rows and processed_rows
    3) Section for Q1: title, subtext (definition), inline SVG bar chart (horizontal Top 3 with percentages and sample sizes)
    4) Section for Q2: same pattern
    5) Section for Q3: horizontal bar chart with median values (display value labels)
    6) Footer: methodology recap (denominators, missing handling, tie-breaking), data source name
- SVGs generated by Matplotlib/Seaborn, exported as SVG strings and embedded directly into the HTML.

## Program Structure (analyze_data.py)
- Main stages in order:
  1) Setup logging (optional) to data_processing.log and console; print detected columns and summary of mappings.
  2) Read Excel (pandas.read_excel, engine='openpyxl').
  3) Normalize column names to a helper map (original -> canonical) using the detection rules above; assert required canonical names found; if not found, gracefully handle and mark corresponding section as "数据不足".
  4) Normalize values: parse multimodal_capability to boolean; bias detection to numeric.
  5) Compute datasets for Q1, Q2, Q3 with sample sizes per group. Build Top 3 lists according to definitions.
  6) Produce three horizontal bar charts (SVG) with:
     - Q1/Q2: x-axis = proportion (0..1), format as percentage labels; bars annotated with "p% (n=X)".
     - Q3: x-axis = median numeric; bars annotated with the median value (sensible rounding).
     - Ensure figure size suitable for mobile (e.g., 600x300 px logical; SVG scales well), font sizes readable.
  7) Compose data-dashboard.html with inline CSS and embedded SVG strings and counts.
  8) Print summary to stdout (Top 3 for each metric) for quick verification.
- Functions (names precise):
  - detect_columns(cols: List[str]) -> Dict[str, str]
  - parse_multimodal(series: pd.Series) -> pd.Series[bool|NaN]
  - compute_top3_multimodal_by(df: pd.DataFrame, group_col: str, mm_col: str) -> pd.DataFrame
  - compute_top3_bias_median(df: pd.DataFrame, group_col: str, bias_col: str) -> pd.DataFrame
  - make_hbar_svg(labels: List[str], values: List[float], annotations: List[str], title: str, xlabel: str, is_percentage: bool=False) -> str
  - build_html(stats: Dict, svg_q1: str|None, svg_q2: str|None, svg_q3: str|None, notes: Dict) -> str
  - main() -> None

## Verification & Fallbacks
- Safe verification runs (no installs):
  - source venv/bin/activate
  - python --version (expect 3.12.x)
  - python -c "import pandas,openpyxl,matplotlib,seaborn,numpy; print('ok')"
  - python analyze_data.py (generates data-dashboard.html)
- If import fails (missing deps), pause and request permission to install into existing venv using pip. If sudo is required, pause for password entry (masked with *).
- If any chart has insufficient data, render a placeholder card stating "数据不足" in that section.

## Deliverables
- analyze_data.py with English comments and Chinese UI text
- data-dashboard.html self-contained static page
- Updated todo file during EXECUTE with progress marks and final review section

---

IMPLEMENTATION CHECKLIST:
1. Activate existing venv and verify Python + key packages are importable.
2. Create analyze_data.py with the program structure and function signatures defined above (no external dependencies beyond venv).
3. Implement column detection and normalization (detect_columns, parse_multimodal) per rules.
4. Implement metrics: compute_top3_multimodal_by for agent_type and model_architecture; compute_top3_bias_median for task_category.
5. Implement SVG chart helper (make_hbar_svg) using Matplotlib/Seaborn for horizontal bar charts with labels and annotations.
6. Implement HTML composer (build_html) with inline CSS, header, stats cards (read_rows & processed_rows), three sections (Q1/Q2/Q3), and footer.
7. Wire up main(): read Excel, normalize, compute metrics, generate SVGs, compose HTML, write data-dashboard.html, and print summary.
8. Run the script inside venv; confirm data-dashboard.html is created and visually check basic layout and text.
9. If imports fail or missing packages are detected, pause and request permission to install into existing venv (no rebuild unless explicitly authorized). If sudo is required, pause for masked password input.
10. If any metric lacks sufficient data, ensure the corresponding section shows a clear "数据不足" placeholder instead of a chart.
11. Append a review section to this todo file after EXECUTE: list implemented steps, any deviations, and verification notes.

